{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8538c1f",
   "metadata": {},
   "source": [
    "# Elaboracion del modelo para el proyecto SENDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ddb92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db559051",
   "metadata": {},
   "outputs": [],
   "source": [
    "seremi_data = {\n",
    "    \"2014\": pd.read_csv(\"raw_data/seremi_2014.csv\"),\n",
    "    \"2015\": pd.read_csv(\"raw_data/seremi_2015.csv\"),\n",
    "    \"2016\": pd.read_csv(\"raw_data/seremi_2016.csv\"),\n",
    "    \"2017\": pd.read_csv(\"raw_data/seremi_2017.csv\"),\n",
    "    \"2018\": pd.read_csv(\"raw_data/seremi_2018.csv\"),\n",
    "    \"2019\": pd.read_csv(\"raw_data/seremi_2019.csv\"),\n",
    "    \"2020\": pd.read_csv(\"raw_data/seremi_2020.csv\"),\n",
    "    \"2021\": pd.read_csv(\"raw_data/seremi_2021.csv\"),\n",
    "    \"2022\": pd.read_csv(\"raw_data/seremi_2022.csv\"),\n",
    "    \"2023\": pd.read_csv(\"raw_data/seremi_2023.csv\"),\n",
    "    \"2024\": pd.read_csv(\"raw_data/seremi_2024.csv\"),\n",
    "    \"2025\": pd.read_csv(\"raw_data/seremi_2025.csv\"),\n",
    "}\n",
    "\n",
    "def procesar_datasets_climaticos(seremi_data_dict):\n",
    "    def grados_a_cardinal(grados):\n",
    "        if pd.isna(grados):\n",
    "            return None\n",
    "        direcciones = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
    "        index = int((grados + 22.5) % 360 // 45)\n",
    "        return direcciones[index]\n",
    "\n",
    "    for año, df in seremi_data_dict.items():\n",
    "\n",
    "        if \"winddirection_10m_dominant\" in df.columns:\n",
    "            df[\"wind_direction_cardinal\"] = df[\"winddirection_10m_dominant\"].apply(grados_a_cardinal)\n",
    "\n",
    "        df = df.rename(columns={\n",
    "            \"temperature_2m_max\": \"Temperatura Máxima\",\n",
    "            \"temperature_2m_min\": \"Temperatura Mínima\",\n",
    "            \"precipitation_sum\": \"Precipitaciones (suma)\",\n",
    "            \"winddirection_10m_dominant\": \"Dirección Viento\"\n",
    "        })\n",
    "\n",
    "        if \"Dirección Viento\" in df.columns:\n",
    "            df = df.drop(columns=[\"Dirección Viento\"])\n",
    "        if \"wind_direction_cardinal\" in df.columns:\n",
    "            df = df.rename(columns={\"wind_direction_cardinal\": \"Dirección del Viento\"})\n",
    "\n",
    "        seremi_data_dict[año] = df\n",
    "\n",
    "    return seremi_data_dict\n",
    "\n",
    "seremi_data = procesar_datasets_climaticos(seremi_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c0cd4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_filtrados = {\n",
    "    \"2014\": \"raw_data/2014_filtrado.csv\",\n",
    "    \"2015\": \"raw_data/2015_filtrado.csv\",\n",
    "    \"2016\": \"raw_data/2016_filtrado.csv\",\n",
    "    \"2017\": \"raw_data/2017_filtrado.csv\",\n",
    "    \"2018\": \"raw_data/2018_filtrado.csv\",\n",
    "    \"2019\": \"raw_data/2019_filtrado.csv\",\n",
    "    \"2020\": \"raw_data/2020_filtrado.csv\",\n",
    "    \"2021\": \"raw_data/2021_filtrado.csv\",\n",
    "    \"2022\": \"raw_data/2022_filtrado.csv\",\n",
    "    \"2023\": \"raw_data/2023_filtrado.csv\",\n",
    "    \"2024\": \"raw_data/2024_filtrado.csv\",\n",
    "    \"2025\": \"raw_data/2025_filtrado.csv\"\n",
    "}\n",
    "\n",
    "filtrado_limpio = {}\n",
    "\n",
    "meses_abreviados = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']\n",
    "\n",
    "columnas_a_eliminar = [\"Cód. SS/SEREMI\", \"Cód. Estab.\", \"Cód. Nivel Cuidado\", \"Acum\", \"Año\"]\n",
    "\n",
    "for año, archivo in archivos_filtrados.items():\n",
    "    df = pd.read_csv(archivo)\n",
    "\n",
    "    df = df[~df[\"Nombre Nivel Cuidado\"].isin([\n",
    "      \"330 - Area Pensionado\",\n",
    "      \"330 - Área Pensionado\",\n",
    "      \"401 - Área Médica Adulto Cuidados Básicos\",\n",
    "      \"402 - Área Médica Adulto Cuidados Medios\",\n",
    "      \"403 - Área Médico-Quirúrgico Cuidados Básicos\",\n",
    "      \"404 - Área Médico-Quirúrgico Cuidados Medios\",\n",
    "      \"405 - Área Cuidados Intensivos Adultos\",\n",
    "      \"406 - Área Cuidados Intermedios Adultos\",\n",
    "      \"407 - Área Médica Pediátrica Cuidados Básicos\",\n",
    "      \"408 - Área Médica Pediátrica Cuidados Medios\",\n",
    "      \"409 - Área Médico-Quirúrgico Pediátrica Cuidados Básicos\",\n",
    "      \"410 - Área Médico-Quirúrgico Pediátrica Cuidados Medios\",\n",
    "      \"411 - Área Cuidados Intensivos Pediátricos\",\n",
    "      \"412 - Área Cuidados Intermedios Pediátricos\",\n",
    "      \"413 - Área Neonatología Cuidados Básicos\",\n",
    "      \"414 - Área Neonatología Cuidados Intensivos\",\n",
    "      \"415 - Área Neonatología Cuidados Intermedios\",\n",
    "      \"416 - Área Obstetricia\",\n",
    "      \"418 - Área Psiquiatría Adulto Corta estadía\",\n",
    "      \"419 - Área Psiquiatría Adulto Mediana estadía\",\n",
    "      \"420 - Área Psiquiatría Adulto Larga estadía\",\n",
    "      \"421 - Área Psiquiatría Infanto-adolescente corta estadía\",\n",
    "      \"427 - Área Sociosanitaria Adulto\",\n",
    "      \"428 - Área de Hospitalización de Cuidados Intensivos en Psiquiatría Adulto\",\n",
    "      \"429 - Área de Hospitalización de Cuidados Intensivos en Psiquiatría Infanto Adolescente\",\n",
    "      \"Área Cuidados Intensivos Adultos\",\n",
    "      \"Área Cuidados Intensivos Pediátricos\",\n",
    "      \"Área Cuidados Intermedios Adultos\",\n",
    "      \"Área Cuidados Intermedios Pediátricos\",\n",
    "      \"Área Médica Adulto Cuidados Básicos\",\n",
    "      \"Área Médica Adulto Cuidados Medios\",\n",
    "      \"Área Médica Pediátrica Cuidados Básicos\",\n",
    "      \"Área Médica Pediátrica Cuidados Medios\",\n",
    "      \"Área Médico-Quirúrgico Cuidados Básicos\",\n",
    "      \"Área Médico-Quirúrgico Cuidados Medios\",\n",
    "      \"Área Médico-Quirúrgico Pediátrica Cuidados Básicos\",\n",
    "      \"Área Médico-Quirúrgico Pediátrica Cuidados Medios\",\n",
    "      \"Área Neonatología Cuidados Básicos\",\n",
    "      \"Área Neonatología Cuidados Intensivos\",\n",
    "      \"Área Neonatología Cuidados Intermedios\",\n",
    "      \"Área Obstetricia\",\n",
    "      \"Área Pensionado\",\n",
    "      \"Área Psiquiatría Adulto Corta estadía\",\n",
    "      \"Área Psiquiatría Adulto Larga estadía\",\n",
    "      \"Área Psiquiatría Adulto Mediana estadía\",\n",
    "      \"Área Psiquiatría Infanto-adolescente corta estadía\"\n",
    "    ]\n",
    "    )].copy()\n",
    "\n",
    "    df = df.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        \"Nombre SS/SEREMI\": \"SEREMI\",\n",
    "        \"Nombre Nivel Cuidado\": \"Area\"\n",
    "    })\n",
    "\n",
    "    nuevo_nombre_columnas = {}\n",
    "    año_int = int(año)\n",
    "\n",
    "    for i, mes_abrev in enumerate(meses_abreviados, start=1):\n",
    "        if mes_abrev in df.columns:\n",
    "            fecha = datetime(año_int, i, 1).strftime('%Y-%m-%d')\n",
    "            nuevo_nombre_columnas[mes_abrev] = fecha\n",
    "\n",
    "    df = df.rename(columns=nuevo_nombre_columnas)\n",
    "\n",
    "    filtrado_limpio[año] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6fbdc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info_hospital_area_todo_el_año(hospital_nombre):\n",
    "    registros = []\n",
    "\n",
    "    for año, df in filtrado_limpio.items():\n",
    "        df_seremi = seremi_data[año].copy()\n",
    "        df_seremi['Mes'] = pd.to_datetime(df_seremi['Mes'], errors='coerce')\n",
    "        df_seremi.dropna(subset=['Mes'], inplace=True)\n",
    "        df_seremi['Mes'] = df_seremi['Mes'].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "        columnas_mes = [col for col in df.columns if col.startswith(\"20\")]\n",
    "        for col in columnas_mes:\n",
    "            df_tmp = df[\n",
    "                (df[\"Nombre Establecimiento\"] == hospital_nombre) &\n",
    "                (df[\"Area\"] == \"Datos Establecimiento\")\n",
    "            ][[\"SEREMI\", \"Nombre Establecimiento\", \"Area\", \"Glosa\", col]].copy()\n",
    "\n",
    "            if df_tmp.empty:\n",
    "                continue\n",
    "\n",
    "            df_tmp = df_tmp.rename(columns={col: \"Valor\"})\n",
    "            df_tmp[\"Fecha\"] = pd.to_datetime(col)\n",
    "\n",
    "            clima_mes = df_seremi[df_seremi[\"Mes\"] == df_tmp[\"Fecha\"].iloc[0]].copy()\n",
    "            df_merge = df_tmp.merge(clima_mes, on=[\"SEREMI\"], how=\"left\")\n",
    "\n",
    "            registros.append(df_merge)\n",
    "\n",
    "    if registros:\n",
    "        return pd.concat(registros, ignore_index=True).sort_values(\"Fecha\")\n",
    "    else:\n",
    "        print(\"⚠️ No se encontraron datos para ese hospital y área.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b74c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_dataset_climatico_avanzado(df):\n",
    "    if 'Area' in df.columns:\n",
    "        df = df[df['Area'] == \"Datos Establecimiento\"].copy()\n",
    "\n",
    "    df_pivot = df.pivot(index='Fecha', columns='Glosa', values='Valor').reset_index()\n",
    "\n",
    "    columnas_necesarias = ['Dias Cama Disponibles', 'Dias Cama Ocupados',\n",
    "                           'Promedio Cama Disponibles', 'Numero de Egresos']\n",
    "    if not all(col in df_pivot.columns for col in columnas_necesarias):\n",
    "        print(\"❌ Datos insuficientes para generar el modelo.\")\n",
    "        return None\n",
    "\n",
    "    clima = df.drop_duplicates(subset='Fecha')[[\n",
    "        'Fecha', 'Temperatura Máxima', 'Temperatura Mínima',\n",
    "        'Precipitaciones (suma)', 'Dirección del Viento'\n",
    "    ]]\n",
    "\n",
    "    df_pivot = pd.merge(df_pivot, clima, on='Fecha', how='left')\n",
    "\n",
    "    df_pivot = pd.get_dummies(df_pivot, columns=['Dirección del Viento'], prefix='Viento')\n",
    "\n",
    "    df_pivot = df_pivot.sort_values('Fecha')\n",
    "\n",
    "    df_pivot['Mes'] = df_pivot['Fecha'].dt.month\n",
    "    df_pivot['Trimestre'] = df_pivot['Fecha'].dt.quarter\n",
    "\n",
    "    df_pivot['lag_1'] = df_pivot['Dias Cama Disponibles'].shift(1)\n",
    "    df_pivot['lag_2'] = df_pivot['Dias Cama Disponibles'].shift(2)\n",
    "    df_pivot['lag_3'] = df_pivot['Dias Cama Disponibles'].shift(3)\n",
    "\n",
    "    df_pivot['media_movil_3'] = df_pivot['Dias Cama Disponibles'].rolling(window=3).mean()\n",
    "\n",
    "    df_pivot['variacion_disponibles'] = df_pivot['Dias Cama Disponibles'].diff()\n",
    "    df_pivot['porcentaje_ocupacion'] = df_pivot['Dias Cama Ocupados'] / df_pivot['Dias Cama Disponibles']\n",
    "    df_pivot['ocupados_media_movil'] = df_pivot['Dias Cama Ocupados'].rolling(window=3).mean()\n",
    "    df_pivot['promedio_media_movil'] = df_pivot['Promedio Cama Disponibles'].rolling(window=3).mean()\n",
    "    df_pivot['egresos_media_movil'] = df_pivot['Numero de Egresos'].rolling(window=3).mean()\n",
    "\n",
    "    df_pivot['Diferencia Térmica'] = df_pivot['Temperatura Máxima'] - df_pivot['Temperatura Mínima']\n",
    "\n",
    "    df_pivot['temp_max_movil'] = df_pivot['Temperatura Máxima'].rolling(window=3).mean()\n",
    "    df_pivot['precipitacion_movil'] = df_pivot['Precipitaciones (suma)'].rolling(window=3).mean()\n",
    "\n",
    "    df_pivot['same_month_last_year'] = df_pivot['Dias Cama Disponibles'].shift(12)\n",
    "    df_pivot['hist_avg_mes'] = df_pivot.groupby('Mes')['Dias Cama Disponibles'].transform('mean')\n",
    "\n",
    "    df_pivot['interaccion_ocupacion_temp'] = df_pivot['porcentaje_ocupacion'] * df_pivot['Temperatura Máxima']\n",
    "    df_pivot['interaccion_precipitacion_disp'] = df_pivot['Precipitaciones (suma)'] * df_pivot['Dias Cama Disponibles']\n",
    "\n",
    "    return df_pivot.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pipeline_final_mae_reducido_arima(hospital):\n",
    "    print(f\"🔍 Extrayendo datos para: {hospital} | Datos Establecimiento\")\n",
    "    # Llamamos a la función de extracción sin el parámetro area, ya que ahora se filtra internamente\n",
    "    df_base = extraer_info_hospital_area_todo_el_año(hospital)\n",
    "\n",
    "    if df_base.empty:\n",
    "        print(\"❌ No se encontraron datos para el hospital o área especificada.\")\n",
    "        return None\n",
    "\n",
    "    print(\"🧪 Preparando dataset con variables hospitalarias, climáticas y derivadas...\")\n",
    "    df_modelo = preparar_dataset_climatico_avanzado(df_base)\n",
    "\n",
    "    if df_modelo is None or df_modelo.empty:\n",
    "        print(\"❌ No se pudo preparar el dataset.\")\n",
    "        return None\n",
    "\n",
    "    # Selección de features\n",
    "    features = [\n",
    "        'Dias Cama Ocupados', 'Promedio Cama Disponibles', 'Numero de Egresos',\n",
    "        'Mes', 'Trimestre', 'lag_1', 'lag_2', 'lag_3', 'media_movil_3',\n",
    "        'porcentaje_ocupacion', 'variacion_disponibles',\n",
    "        'ocupados_media_movil', 'promedio_media_movil', 'egresos_media_movil',\n",
    "        'Temperatura Máxima', 'Temperatura Mínima', 'Precipitaciones (suma)',\n",
    "        'Diferencia Térmica', 'temp_max_movil', 'precipitacion_movil',\n",
    "        'same_month_last_year', 'hist_avg_mes',\n",
    "        'interaccion_ocupacion_temp', 'interaccion_precipitacion_disp'\n",
    "    ] + [col for col in df_modelo.columns if col.startswith('Viento_')]\n",
    "\n",
    "    # División temporal\n",
    "    df_modelo = df_modelo.set_index('Fecha')  # Asegúrate de que la fecha esté como índice\n",
    "    y = df_modelo['Dias Cama Disponibles']\n",
    "\n",
    "    # Separar en entrenamiento y test\n",
    "    train_size = int(len(df_modelo) * 0.8)\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    print(\"🔧 Ajustando modelo ARIMA...\")\n",
    "\n",
    "    # Ajustamos el modelo ARIMA\n",
    "    model = ARIMA(y_train, order=(5, 1, 0))  # Puedes ajustar el orden (p, d, q)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    print(\"📊 Evaluando sobre el 20% final de los datos...\")\n",
    "\n",
    "    # Predicción\n",
    "    y_pred = model_fit.forecast(steps=len(y_test))\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "    error_pct = np.mean(np.abs((y_test.values - y_pred) / y_test.values)) * 100\n",
    "\n",
    "    # Resultado detallado con valores reales y predichos\n",
    "    resultados = pd.DataFrame({\n",
    "        'Fecha': y_test.index,\n",
    "        'Real': y_test.values,                  # Valores reales observados\n",
    "        'Predicho': y_pred,                     # Valores predichos por el modelo\n",
    "        'Error Absoluto': np.abs(y_test.values - y_pred),\n",
    "        'Error Porcentual (%)': np.abs((y_test.values - y_pred) / y_test.values) * 100\n",
    "    })\n",
    "\n",
    "    # Reporte resumen\n",
    "    print(f\"✅ MAE (camas): {mae:.2f}\")\n",
    "    print(f\"✅ RMSE (camas): {rmse:.2f}\")\n",
    "    print(f\"📉 Error promedio porcentual: {error_pct:.2f}%\")\n",
    "\n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa41c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ari=pipeline_final_mae_reducido_arima(\"Hospital Barros Luco Trudeau (Santiago, San Miguel)\")\n",
    "print(res_ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07879107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "def pipeline_final_mae_reducido_sarima(hospital):\n",
    "    print(f\"🔍 Extrayendo datos para: {hospital} | Datos Establecimiento\")\n",
    "    # Extracción de datos\n",
    "    df_base = extraer_info_hospital_area_todo_el_año(hospital)\n",
    "\n",
    "    if df_base.empty:\n",
    "        print(\"❌ No se encontraron datos para el hospital o área especificada.\")\n",
    "        return None\n",
    "\n",
    "    print(\"🧪 Preparando dataset con variables hospitalarias, climáticas y derivadas...\")\n",
    "    df_modelo = preparar_dataset_climatico_avanzado(df_base)\n",
    "\n",
    "    if df_modelo is None or df_modelo.empty:\n",
    "        print(\"❌ No se pudo preparar el dataset.\")\n",
    "        return None\n",
    "\n",
    "    features = [\n",
    "        'Dias Cama Ocupados', 'Promedio Cama Disponibles', 'Numero de Egresos',\n",
    "        'Mes', 'Trimestre', 'lag_1', 'lag_2', 'lag_3', 'media_movil_3',\n",
    "        'porcentaje_ocupacion', 'variacion_disponibles',\n",
    "        'ocupados_media_movil', 'promedio_media_movil', 'egresos_media_movil',\n",
    "        'Temperatura Máxima', 'Temperatura Mínima', 'Precipitaciones (suma)',\n",
    "        'Diferencia Térmica', 'temp_max_movil', 'precipitacion_movil',\n",
    "        'same_month_last_year', 'hist_avg_mes',\n",
    "        'interaccion_ocupacion_temp', 'interaccion_precipitacion_disp'\n",
    "    ] + [col for col in df_modelo.columns if col.startswith('Viento_')]\n",
    "\n",
    "    # División temporal\n",
    "    df_modelo = df_modelo.set_index('Fecha')\n",
    "    y = df_modelo['Dias Cama Disponibles']\n",
    "\n",
    "    train_size = int(len(df_modelo) * 0.8)\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    print(\"🔧 Ajustando modelo SARIMA...\")\n",
    "    # Ajustando el modelo SARIMA\n",
    "    model = SARIMAX(y_train, order=(5, 1, 0), seasonal_order=(1, 1, 1, 12))  # Ajusta estacionalidad\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    print(\"📊 Evaluando sobre el 20% final de los datos...\")\n",
    "\n",
    "    # Predicción\n",
    "    y_pred = model_fit.forecast(steps=len(y_test))\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "    error_pct = np.mean(np.abs((y_test.values - y_pred) / y_test.values)) * 100\n",
    "\n",
    "    # Resultado detallado con valores reales y predichos\n",
    "    resultados = pd.DataFrame({\n",
    "        'Fecha': y_test.index,\n",
    "        'Real': y_test.values,\n",
    "        'Predicho': y_pred,\n",
    "        'Error Absoluto': np.abs(y_test.values - y_pred),\n",
    "        'Error Porcentual (%)': np.abs((y_test.values - y_pred) / y_test.values) * 100\n",
    "    })\n",
    "\n",
    "    # Reporte resumen\n",
    "    print(f\"✅ MAE (camas): {mae:.2f}\")\n",
    "    print(f\"✅ RMSE (camas): {rmse:.2f}\")\n",
    "    print(f\"📉 Error promedio porcentual: {error_pct:.2f}%\")\n",
    "\n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a961063",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sari=pipeline_final_mae_reducido_sarima(\"Hospital Barros Luco Trudeau (Santiago, San Miguel)\")\n",
    "print(res_sari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_hospitales_validos(filtrado_limpio):\n",
    "    hospitales = set()\n",
    "    for df in filtrado_limpio.values():\n",
    "        if \"Nombre Establecimiento\" in df.columns and \"Area\" in df.columns:\n",
    "            validos = df[df[\"Area\"] == \"Datos Establecimiento\"][[\"Nombre Establecimiento\"]].dropna().drop_duplicates()\n",
    "            for _, row in validos.iterrows():\n",
    "                hospitales.add(row[\"Nombre Establecimiento\"])\n",
    "    return sorted(list(hospitales))\n",
    "\n",
    "hospitales_validos = extraer_hospitales_validos(filtrado_limpio)\n",
    "hospitales_a_evaluar = hospitales_validos[:30]\n",
    "\n",
    "def pipeline_final_mae_reducido_sarima(hospital):\n",
    "    print(f\"🔍 Extrayendo datos para: {hospital} | Datos Establecimiento\")\n",
    "    df_base = extraer_info_hospital_area_todo_el_año(hospital)\n",
    "\n",
    "    if df_base.empty:\n",
    "        print(\"❌ No se encontraron datos para el hospital o área especificada.\")\n",
    "        return None\n",
    "\n",
    "    print(\"🧪 Preparando dataset con variables hospitalarias, climáticas y derivadas...\")\n",
    "    df_modelo = preparar_dataset_climatico_avanzado(df_base)\n",
    "\n",
    "    if df_modelo is None or df_modelo.empty:\n",
    "        print(\"❌ No se pudo preparar el dataset.\")\n",
    "        return None\n",
    "\n",
    "    features = [\n",
    "        'Dias Cama Ocupados', 'Promedio Cama Disponibles', 'Numero de Egresos',\n",
    "        'Mes', 'Trimestre', 'lag_1', 'lag_2', 'lag_3', 'media_movil_3',\n",
    "        'porcentaje_ocupacion', 'variacion_disponibles',\n",
    "        'ocupados_media_movil', 'promedio_media_movil', 'egresos_media_movil',\n",
    "        'Temperatura Máxima', 'Temperatura Mínima', 'Precipitaciones (suma)',\n",
    "        'Diferencia Térmica', 'temp_max_movil', 'precipitacion_movil',\n",
    "        'same_month_last_year', 'hist_avg_mes',\n",
    "        'interaccion_ocupacion_temp', 'interaccion_precipitacion_disp'\n",
    "    ] + [col for col in df_modelo.columns if col.startswith('Viento_')]\n",
    "\n",
    "    df_modelo = df_modelo.set_index('Fecha')\n",
    "    y = df_modelo['Dias Cama Disponibles']\n",
    "\n",
    "    train_size = int(len(df_modelo) * 0.8)\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    print(\"🔧 Ajustando modelo SARIMA...\")\n",
    "    model = SARIMAX(y_train, order=(5, 1, 0), seasonal_order=(1, 1, 1, 12))\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    print(\"📊 Evaluando sobre el 20% final de los datos...\")\n",
    "\n",
    "    y_pred = model_fit.forecast(steps=len(y_test))\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "    error_pct = np.mean(np.abs((y_test.values - y_pred) / y_test.values)) * 100\n",
    "\n",
    "    resultados = pd.DataFrame({\n",
    "        'Fecha': y_test.index,\n",
    "        'Real': y_test.values,\n",
    "        'Predicho': y_pred,\n",
    "        'Error Absoluto': np.abs(y_test.values - y_pred),\n",
    "        'Error Porcentual (%)': np.abs((y_test.values - y_pred) / y_test.values) * 100\n",
    "    })\n",
    "\n",
    "    print(f\"✅ MAE (camas): {mae:.2f}\")\n",
    "    print(f\"✅ RMSE (camas): {rmse:.2f}\")\n",
    "    print(f\"📉 Error promedio porcentual: {error_pct:.2f}%\")\n",
    "\n",
    "    return resultados\n",
    "\n",
    "resultados_todos = {}\n",
    "\n",
    "for hospital in hospitales_a_evaluar:\n",
    "    try:\n",
    "        print(\"\\n==========================\")\n",
    "        print(f\"🏥 Evaluando: {hospital}\")\n",
    "        print(\"==========================\")\n",
    "        resultados = pipeline_final_mae_reducido_sarima(hospital)\n",
    "        if resultados is not None:\n",
    "            resultados_todos[hospital] = resultados\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en {hospital}: {e}\")\n",
    "        continue\n",
    "\n",
    "tabla_resumen = []\n",
    "\n",
    "for hospital, resultados in resultados_todos.items():\n",
    "    if \"Error Absoluto\" in resultados.columns and \"Error Porcentual (%)\" in resultados.columns:\n",
    "        mae = resultados[\"Error Absoluto\"].mean()\n",
    "        error_pct = resultados[\"Error Porcentual (%)\"].mean()\n",
    "        tabla_resumen.append({\n",
    "            \"Hospital\": hospital,\n",
    "            \"MAE (camas)\": round(mae, 2),\n",
    "            \"Error Porcentual Promedio (%)\": round(error_pct, 2)\n",
    "        })\n",
    "\n",
    "df_tabla_resumen = pd.DataFrame(tabla_resumen).sort_values(\"MAE (camas)\").reset_index(drop=True)\n",
    "display(df_tabla_resumen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2da32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "def pipeline_final_mae_reducido_lightgbm(hospital):\n",
    "    print(f\"🔍 Extrayendo datos para: {hospital} | Datos Establecimiento\")\n",
    "    df_base = extraer_info_hospital_area_todo_el_año(hospital)\n",
    "\n",
    "    if df_base.empty:\n",
    "        print(\"❌ No se encontraron datos para el hospital o área especificada.\")\n",
    "        return None\n",
    "\n",
    "    print(\"🧪 Preparando dataset con variables hospitalarias, climáticas y derivadas...\")\n",
    "    df_modelo = preparar_dataset_climatico_avanzado(df_base)\n",
    "\n",
    "    if df_modelo is None or df_modelo.empty:\n",
    "        print(\"❌ No se pudo preparar el dataset.\")\n",
    "        return None\n",
    "\n",
    "    features = [\n",
    "        'Dias Cama Ocupados', 'Promedio Cama Disponibles', 'Numero de Egresos',\n",
    "        'Mes', 'Trimestre', 'lag_1', 'lag_2', 'lag_3', 'media_movil_3',\n",
    "        'porcentaje_ocupacion', 'variacion_disponibles',\n",
    "        'ocupados_media_movil', 'promedio_media_movil', 'egresos_media_movil',\n",
    "        'Temperatura Máxima', 'Temperatura Mínima', 'Precipitaciones (suma)',\n",
    "        'Diferencia Térmica', 'temp_max_movil', 'precipitacion_movil',\n",
    "        'same_month_last_year', 'hist_avg_mes',\n",
    "        'interaccion_ocupacion_temp', 'interaccion_precipitacion_disp'\n",
    "    ] + [col for col in df_modelo.columns if col.startswith('Viento_')]\n",
    "\n",
    "    df_modelo = df_modelo.set_index('Fecha')\n",
    "    y = df_modelo['Dias Cama Disponibles']\n",
    "    X = df_modelo[features]\n",
    "\n",
    "    # División de los datos en entrenamiento y prueba\n",
    "    train_size = int(len(df_modelo) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    print(\"🔧 Ajustando modelo LightGBM...\")\n",
    "\n",
    "    # Ajustando el modelo LightGBM\n",
    "    model = lgb.LGBMRegressor(objective='regression', metric='l2', boosting_type='gbdt')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"📊 Evaluando sobre el 20% final de los datos...\")\n",
    "\n",
    "    # Predicción\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Cálculo de métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "    error_pct = np.mean(np.abs((y_test.values - y_pred) / y_test.values)) * 100\n",
    "\n",
    "    # Resultado detallado con valores reales y predichos\n",
    "    resultados = pd.DataFrame({\n",
    "        'Fecha': y_test.index,\n",
    "        'Real': y_test.values,\n",
    "        'Predicho': y_pred,\n",
    "        'Error Absoluto': np.abs(y_test.values - y_pred),\n",
    "        'Error Porcentual (%)': np.abs((y_test.values - y_pred) / y_test.values) * 100\n",
    "    })\n",
    "\n",
    "    # Reporte resumen\n",
    "    print(f\"✅ MAE (camas): {mae:.2f}\")\n",
    "    print(f\"✅ RMSE (camas): {rmse:.2f}\")\n",
    "    print(f\"📉 Error promedio porcentual: {error_pct:.2f}%\")\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a0ee677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Extrayendo datos para: Hospital Barros Luco Trudeau (Santiago, San Miguel) | Datos Establecimiento\n",
      "🧪 Preparando dataset con variables hospitalarias, climáticas y derivadas...\n",
      "🔧 Ajustando modelo LightGBM...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 22636.958763\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "📊 Evaluando sobre el 20% final de los datos...\n",
      "✅ MAE (camas): 999.32\n",
      "✅ RMSE (camas): 1484.74\n",
      "📉 Error promedio porcentual: 4.65%\n",
      "        Fecha     Real      Predicho  Error Absoluto  Error Porcentual (%)\n",
      "0  2023-02-01  18759.0  20422.789061     1663.789061              8.869284\n",
      "1  2023-03-01  21183.0  21839.723149      656.723149              3.100237\n",
      "2  2023-04-01  20731.0  20992.113617      261.113617              1.259532\n",
      "3  2023-05-01  21618.0  21781.481122      163.481122              0.756227\n",
      "4  2023-06-01  20804.0  21086.017361      282.017361              1.355592\n",
      "5  2023-07-01  21456.0  21817.041981      361.041981              1.682709\n",
      "6  2023-08-01  21494.0  21783.692472      289.692472              1.347783\n",
      "7  2023-09-01  21119.0  21395.850889      276.850889              1.310909\n",
      "8  2023-10-01  21913.0  21825.632974       87.367026              0.398700\n",
      "9  2023-11-01  21247.0  21111.343619      135.656381              0.638473\n",
      "10 2023-12-01  29777.0  24131.424862     5645.575138             18.959516\n",
      "11 2024-01-01  20166.0  21102.780020      936.780020              4.645344\n",
      "12 2024-02-01  19168.0  20511.576609     1343.576609              7.009477\n",
      "13 2024-03-01  20469.0  21594.669124     1125.669124              5.499385\n",
      "14 2024-04-01  19482.0  20594.963169     1112.963169              5.712777\n",
      "15 2024-05-01  20382.0  21647.239707     1265.239707              6.207633\n",
      "16 2024-06-01  20466.0  21435.664176      969.664176              4.737927\n",
      "17 2024-07-01  21113.0  21760.936244      647.936244              3.068897\n",
      "18 2024-08-01  21081.0  21630.298238      549.298238              2.605656\n",
      "19 2024-09-01  20547.0  21381.527711      834.527711              4.061555\n",
      "20 2024-10-01  21216.0  21880.005696      664.005696              3.129740\n",
      "21 2024-11-01  20278.0  20850.129288      572.129288              2.821429\n",
      "22 2024-12-01  20057.0  21424.829097     1367.829097              6.819709\n",
      "23 2025-01-01  19979.0  21292.277313     1313.277313              6.573289\n",
      "24 2025-02-01  18021.0  20477.901330     2456.901330             13.633546\n"
     ]
    }
   ],
   "source": [
    "res_lgbm = pipeline_final_mae_reducido_lightgbm(\"Hospital Barros Luco Trudeau (Santiago, San Miguel)\")\n",
    "print(res_lgbm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SENDA_Chile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
